# Capitulo 2: Las piezas que componen un lenguaje

| [â†©ï¸ Volver al inicio del Proyecto](../README.md) | [â¬…ï¸ Ir a CapÃ­tulo 1](../docs/01-Bienvenido.md) |
| :----------------------------------------------: | :--------------------------------------------: |

<br/><hr/><br/>

Desde siempre hemos buscado que las computadoras **entiendan nuestras instrucciones**, y por eso creamos **lenguajes de programaciÃ³n**.

Aunque las mÃ¡quinas sean hoy mÃ¡s rÃ¡pidas, los principios para construir un lenguaje **siguen siendo los mismos**.

Este capÃ­tulo ofrece una **visiÃ³n panorÃ¡mica** de compiladores, intÃ©rpretes, JIT, VM y runtime. No necesitas memorizar todo; lo importante es **ver cÃ³mo se conectan las piezas** y usar este mapa como guÃ­a para los prÃ³ximos capÃ­tulos.

<br/><hr/><br/>

# ğŸ“š Ãndice del CapÃ­tulo 2

| SecciÃ³n                                                                                                                                      | DescripciÃ³n                                                                                                                   |
| :------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------- |
| [1. âœï¸ Dibujando el lenguaje en un papel](#1-ï¸-dibujando-el-lenguaje-en-un-papel)                                                            | CÃ³mo un boceto inicial se convierte en un mapa claro del programa.                                                            |
| [2. ğŸ” Escaneo (Scanning o Lexing)](#2--escaneo-scanning-o-lexing)                                                                           | Primer paso: convertir texto crudo en tokens listos para el anÃ¡lisis.                                                         |
| [3. ğŸ‘€ Â¿QuÃ© es el escÃ¡ner lÃ©xico (lexer)?](#3--quÃ©-es-el-escÃ¡ner-lÃ©xico-o-lexer)                                                             | ExplicaciÃ³n de cÃ³mo el lexer organiza caracteres en bloques significativos.                                                   |
| [4. ğŸ§© Â¿QuÃ© es un token?](#4--quÃ©-es-un-token)                                                                                               | Concepto de token y ejemplos prÃ¡cticos de los distintos tipos.                                                                |
| [5. ğŸ”§ De texto a tokens: primer paso del compilador](#5--de-texto-a-tokens-primer-paso-del-compilador)                                      | CÃ³mo el lexer encaja en el proceso general del compilador.                                                                    |
| [6. ğŸŒ² AnÃ¡lisis SintÃ¡ctico (Parsing)](#6--anÃ¡lisis-sintÃ¡ctico-parsing)                                                                       | CÃ³mo los tokens se organizan en estructuras jerÃ¡rquicas (AST).                                                                |
| [7. ğŸ’¬ AnÃ¡lisis SemÃ¡ntico: Entendiendo el Significado del CÃ³digo](#7--anÃ¡lisis-semÃ¡ntico-entendiendo-el-significado-del-cÃ³digo)              | Verifica que el programa tenga sentido lÃ³gico y coherente segÃºn las reglas del lenguaje.                                      |
| [8. ğŸ› ï¸ Representaciones Intermedias (Intermediate Representations â€“ IR)](#8-ï¸-representaciones-intermedias-intermediate-representations--ir) | Forma intermedia de cÃ³digo que conecta el front end y back end, facilitando optimizaciÃ³n y soporte multi-lenguaje.            |
| [9. âš¡ OptimizaciÃ³n (Optimization)](#9--optimizaciÃ³n-optimization)                                                                           | CÃ³mo mejorar el cÃ³digo para que sea mÃ¡s rÃ¡pido o eficiente sin cambiar su funcionamiento.                                     |
| [10. ğŸ’» GeneraciÃ³n de CÃ³digo (Code Generation)](#10--generaciÃ³n-de-cÃ³digo-code-generation)                                                   | Convertir la representaciÃ³n intermedia optimizada en instrucciones que la mÃ¡quina pueda ejecutar.                             |
| [11. ğŸ–¥ï¸ MÃ¡quina Virtual (Virtual Machine â€“ VM)](#11-ï¸-mÃ¡quina-virtual-virtual-machine--vm)                                                   | Ejecutar bytecode en una mÃ¡quina virtual o generar mini-compiladores para cada arquitectura.                                  |
| [12. â±ï¸ Tiempo de EjecuciÃ³n (Runtime)](#12-ï¸-tiempo-de-ejecuciÃ³n-runtime)                                                                    | Servicios necesarios durante la ejecuciÃ³n, como garbage collector, rastreo de tipos y librerÃ­as estÃ¡ndar.                     |
| [13. ğŸ›£ï¸ Atajos y rutas alternativas](#13-ï¸-atajos-y-rutas-alternativas)                                                                      | Compiladores de un solo paso y traducciÃ³n dirigida por la sintaxis para simplificar el pipeline de compilaciÃ³n.               |
| [14. ğŸŒ³ IntÃ©rpretes de recorrido de Ã¡rbol (Tree-walk interpreters)](#14--intÃ©rpretes-de-recorrido-de-Ã¡rbol-tree-walk-interpreters)           | Ejecutar directamente el AST, ideal para lenguajes educativos o proyectos pequeÃ±os, aunque lento.                             |
| [15. ğŸ”„ Transpilador (Transpiler)](#15--transpilador-transpiler)                                                                             | Traducir cÃ³digo de un lenguaje a otro de alto nivel, usando el lenguaje destino como IR intermedia.                           |
| [16. âœ¨ CompilaciÃ³n Just-in-Time (JIT)](#16--compilaciÃ³n-just-in-time-jit)                                                                   | Compilar al vuelo a cÃ³digo nativo, combinando portabilidad y rendimiento, con optimizaciÃ³n dinÃ¡mica de â€œhot spotsâ€.           |
| [17. ğŸ“š Compiladores e IntÃ©rpretes (Compilers and Interpreters)](#17--compiladores-e-intÃ©rpretes-compilers-and-interpreters)                 | Diferencias entre compiladores e intÃ©rpretes, ejemplos y cÃ³mo los lenguajes modernos combinan ambos enfoques.                 |
| [18. ğŸ“ Ejercicio Propuesto](#18--ejercicio-propuesto-en-desarrollo)                                                                                       | Explora el cÃ³digo fuente de un intÃ©rprete o compilador open source para identificar cÃ³mo convierte el cÃ³digo en tokens y AST. |

<br/><hr/><br/>

## 1. âœï¸ Dibujando el lenguaje en un papel

Pensemos que crear un lenguaje empieza como un **boceto**. Nada grandioso, solo una idea garabateada con entusiasmo.

![mapa del lenguaje](../recursos/tema-02/img/mapa.png)

Al principio, el programa es **solo texto crudo** â€”una lista de sÃ­mbolos sin mucho sentido por sÃ­ mismos. Pero poco a poco, vamos **trazando lÃ­neas, conectando ideas y dÃ¡ndole forma**. Cada paso nos ayuda a **organizar y entender mejor** lo que el cÃ³digo quiere expresar.

Al final, este garabato lleno de rayones se convierte en un **mapa claro del programa**.

> Todo gran lenguaje empezÃ³ alguna vez como un garabato en un papel.

Nuestro recorrido comienza con el **texto en bruto del cÃ³digo fuente** del usuario.

A lo largo de la historia, hubo muchos intentos fallidos y caminos sin salida: ideas que parecÃ­an prometedoras, pero que el tiempo dejÃ³ atrÃ¡s. Aun asÃ­, esos experimentos forman parte del mapa de la computaciÃ³n y nos recuerdan que incluso los errores ayudan a construir el conocimiento.

<br/><hr/><br/>

## 2. ğŸ” Escaneo (Scanning o Lexing)

El primer paso para entender el cÃ³digo es el **escaneo**, tambiÃ©n llamado **anÃ¡lisis lÃ©xico**.

En esta etapa, el programa deja de ser una simple secuencia de letras y sÃ­mbolos y se convierte en una lista de **tokens** â€”las â€œpalabrasâ€ del lenguaje.

Un **scanner** (o **lexer**) lee el texto y lo divide en partes con significado:  
nÃºmeros, nombres, parÃ©ntesis, operadores o cadenas.

Al mismo tiempo, ignora lo que no aporta nada al cÃ³digo, como los **espacios en blanco** o los **comentarios**.

El resultado es una secuencia limpia y ordenada de tokens.

<br/><hr/><br/>

## 3. ğŸ‘€ Â¿QuÃ© es el escÃ¡ner lÃ©xico (o lexer)?

Cuando escribes un programa, lo que tienes es texto plano: letras, nÃºmeros, signos y espacios.

Por ejemplo:

```javascript
var suma = 10 + 5;
```

Para una computadora, eso al principio es solo una cadena de caracteres:

```java
v a r   s u m a   =   1 0   +   5 ;
```

El escÃ¡ner lÃ©xico (tambiÃ©n llamado **lexer**) es el encargado de leer ese texto y darle estructura, separÃ¡ndolo en bloques con significado, llamados **tokens**.

<br/><hr/><br/>

## 4. ğŸ§© Â¿QuÃ© es un token?

Un token es como una pequeÃ±a etiqueta que indica quÃ© tipo de cosa representa una parte del cÃ³digo. Por ejemplo, el cÃ³digo anterior se convertirÃ­a en esta lista de tokens:

| Texto  | Tipo de token | DescripciÃ³n        |
| :----- | :------------ | :----------------- |
| `var`  | KEYWORD       | Palabra reservada  |
| `suma` | IDENTIFICADOR | Nombre de variable |
| `=`    | OPERADOR      | AsignaciÃ³n         |
| `10`   | NÃšMERO        | Valor numÃ©rico     |
| `+`    | OPERADOR      | Suma               |
| `5`    | NÃšMERO        | Valor numÃ©rico     |
| `;`    | PUNTUACIÃ“N    | Fin de instrucciÃ³n |

El escÃ¡ner tambiÃ©n puede guardar la posiciÃ³n (lÃ­nea y columna) de cada token.
Esto sirve para que, si hay un error, el compilador pueda decirte exactamente dÃ³nde ocurriÃ³.

<br/><hr/><br/>

## 5. ğŸ”§ De texto a tokens: primer paso del compilador

El lexer es la primera etapa del proceso de compilaciÃ³n o interpretaciÃ³n:

```text
ğŸ”  Texto crudo  â†’  ğŸ§® Tokens  â†’  ğŸ§± Estructura del programa
   (Scanner)        (Parser)
```

Primero, el **scanner** divide el texto en tokens.  
DespuÃ©s, el **parser** (analizador sintÃ¡ctico) toma esos tokens y los **organiza** segÃºn las reglas del lenguaje.

Cada etapa se apoya en la anterior: el escaneo prepara el terreno, y el parser empieza a darle forma al cÃ³digo para que el lenguaje pueda interpretarlo o compilarlo correctamente

<br/><hr/><br/>

## 6. ğŸŒ² AnÃ¡lisis SintÃ¡ctico (Parsing)

El siguiente paso despuÃ©s del escaneo es el **parsing**, o anÃ¡lisis sintÃ¡ctico.  
AquÃ­ es donde el cÃ³digo empieza a **tomar forma**: el parser entiende cÃ³mo juntar las piezas (tokens) para formar expresiones y sentencias mÃ¡s grandes.

Un **parser** toma la secuencia de tokens y la organiza en una **estructura jerÃ¡rquica**, mostrando cÃ³mo las distintas partes del cÃ³digo se relacionan entre sÃ­ ğŸŒ³. En la prÃ¡ctica, esa estructura se llama **Ã¡rbol de sintaxis** o **AST** (Abstract Syntax Tree).

Para nosotros, lo importante es entender que **el parser da forma y sentido al cÃ³digo**, y nos permite trabajar con Ã©l de manera ordenada.

**ğŸ’¡ Apunte tÃ©cnico**

El parser **convierte la lista de tokens** en una **estructura organizada** (AST = â€œÃ¡rbol de sintaxis abstractaâ€ o "abstract syntax tree") que refleja la lÃ³gica y jerarquÃ­a del programa.  
Esta estructura es clave para los siguientes pasos del compilador o intÃ©rprete, como:

- Revisar que el cÃ³digo tenga sentido (**anÃ¡lisis semÃ¡ntico**)
- Generar cÃ³digo que la mÃ¡quina pueda ejecutar
- Optimizar el programa para que sea mÃ¡s rÃ¡pido o eficiente

Por lo tanto:

ğŸŸï¸ Tokens â†’ ğŸŒ³ Ãrbol de sintaxis â†’ ğŸ—ï¸ Estructura lÃ³gica del programa

> ğŸ’¡ Sin parsing, el compilador verÃ­a solo una lista de sÃ­mbolos sin sentido.  
> Con Ã©l, el cÃ³digo **adquiere forma, jerarquÃ­a y lÃ³gica**, listo para ser entendido y procesado.

<br/><hr/><br/>

## 7. ğŸ’¬ AnÃ¡lisis SemÃ¡ntico: Entendiendo el Significado del CÃ³digo

> Hasta ahora, ya tenemos nuestro cÃ³digo dividido en tokens (gracias al lexer) y organizado en una estructura lÃ³gica (gracias al parser). Peroâ€¦ Â¿el programa tiene sentido? â“

Por ejemplo, mira este cÃ³digo:

```javascript
var x = "hola";
x = x + 10;
```

El parser no ve ningÃºn problema aquÃ­: la estructura estÃ¡ bien. Pero, desde el punto de vista del significado, algo estÃ¡ mal. Â¡Estamos intentando sumar un nÃºmero a una cadena de texto! Y ahÃ­ es donde entra en juego el anÃ¡lisis semÃ¡ntico.

<br/>

ğŸ” **Â¿QuÃ© hace el anÃ¡lisis semÃ¡ntico?**

El anÃ¡lisis semÃ¡ntico revisa que las operaciones y relaciones del programa tengan **sentido lÃ³gico**, segÃºn las reglas del lenguaje.

Algunas tareas comunes del anÃ¡lisis semÃ¡ntico son:

Tarea DescripciÃ³n
| VerificaciÃ³n | DescripciÃ³n |
| :--------------- | :------------------------------------------------------------ |
| **Tipos** | Que las operaciones sean vÃ¡lidas (no sumar texto con nÃºmeros). |
| **Nombres** | Que las variables y funciones existan antes de usarlas. |
| **Ãmbito (scope)** | QuÃ© variables son visibles dentro de cada bloque. |

Por ejemplo:

- Podemos imaginarlo como una fÃ¡brica de ideas ğŸ­. **Primero**, el **lexer** corta la materia prima en piezas pequeÃ±as (los **tokens**). DespuÃ©s, el **parser** ensambla esas piezas en un producto con forma (el **Ãrbol de sintaxis AST**). Y finalmente, el **analizador semÃ¡ntico** revisa que todo funcione correctamente antes de salir al mundo â€”que las piezas encajen y el resultado tenga sentido âš™ï¸.

| Etapa         | Resultado esperado   |
| :------------ | :------------------- |
| **Lexer**     | Palabras correctas   |
| **Parser**    | Oraciones correctas  |
| **SemÃ¡ntico** | Significado correcto |

<br/>

### ğŸ§° Â¿QuÃ© obtiene el compilador de esta etapa?

DespuÃ©s de este paso, el compilador tiene un programa que:

- Tiene estructura correcta (gracias al parser)
- Tiene significado vÃ¡lido (gracias al anÃ¡lisis semÃ¡ntico)

En otras palabras, el cÃ³digo no solo estÃ¡ bien escrito, sino que tiene lÃ³gica. Y con eso, ya estÃ¡ listo para pasar a las siguientes fases del viaje: la **generaciÃ³n de cÃ³digo** o la **interpretaciÃ³n** ğŸ¯.

<br/>

### ğŸ’¬ Entonces, tenemos el siguiente camino recorrido:

| Etapa         | QuÃ© hace                  | Resultado                    |
| :------------ | :------------------------ | :--------------------------- |
| **Lexer**     | Divide el texto en tokens | ğŸ§© Lista de tokens           |
| **Parser**    | Da estructura al cÃ³digo   | ğŸŒ³ Ãrbol de sintaxis (AST)   |
| **SemÃ¡ntico** | Verifica el significado   | âœ… CÃ³digo coherente y vÃ¡lido |

Sin anÃ¡lisis semÃ¡ntico, podrÃ­amos tener programas â€œbien escritosâ€ pero completamente absurdos.

<br/><hr/><br/>

## 8. ğŸ› ï¸ Representaciones Intermedias (Intermediate Representations â€“ IR)

Podemos imaginar el **compilador** como una tuberÃ­a de trabajo donde cada etapa transforma el cÃ³digo del usuario en una forma mÃ¡s organizada y fÃ¡cil de procesar ğŸ—ï¸.

El **front-end** de esta tuberÃ­a estÃ¡ ligado al lenguaje fuente (por ejemplo, Java, C o Python) ğŸ“œ.

El **back-end**, en cambio, se enfoca en la arquitectura destino (como x86, ARM o RISC-V) âš™ï¸.

En el medio, el cÃ³digo pasa por una **representaciÃ³n intermedia (IR)**: una forma neutra que no depende del lenguaje original ni de la mÃ¡quina final ğŸ§©. Esta IR actÃºa como un puente entre ambos mundos, permitiendo que un compilador soporte mÃºltiples lenguajes y plataformas con menos esfuerzo.

ğŸ’¡ **Ejemplo**

Supongamos que queremos crear compiladores para Pascal, C y Fortran, y que apunten a tres arquitecturas: x86, ARM y SPARC. Sin **IR**, tendrÃ­as que construir nueve compiladores completos (una combinaciÃ³n por cada caso) ğŸ˜µâ€ğŸ’«.

Con una **IR compartida**, solo necesitas:
Un **front-end** por lenguaje (que genere la IR).
Un **back-end** por arquitectura (que traduzca desde la IR).

De esta forma, puedes mezclar y combinar libremente todas las combinaciones posibles.

<br/>

**ğŸ”§ Tipos comunes de IR**

Existen varios estilos de representaciÃ³n intermedia que se usan ampliamente en compiladores modernos ğŸ“š: Control Flow Graph (CFG) ğŸŒ³ - Static Single Assignment (SSA) âœï¸ - Continuation-Passing Style (CPS) ğŸ”— - Three-Address Code (TAC) ğŸ§®

Por lo tanto:
ğŸ“œ Lenguaje fuente â†’ ğŸŒ³ RepresentaciÃ³n intermedia (IR) â†’ ğŸ–¥ï¸ Arquitectura objetivo

La **representaciÃ³n intermedia (IR)** desacopla el front-end del back-end, haciendo el compilador modular, extensible y reutilizable. TambiÃ©n permite aplicar optimizaciones independientes del lenguaje o la plataforma, lo que mejora la eficiencia general del programa.

<br/>

**ğŸ’¡ Dato curioso: Soporte de mÃºltiples lenguajes y arquitecturas en GCC**

- GCC significa GNU Compiler Collection: Es un conjunto de compiladores de cÃ³digo abierto desarrollado por el proyecto GNU que permite traducir programas escritos en varios lenguajes de programaciÃ³n a cÃ³digo mÃ¡quina que pueda ejecutar una computadora.

Â¿Alguna vez te preguntaste cÃ³mo GCC puede compilar tantos lenguajes para tantas arquitecturas distintas?

La clave estÃ¡ en que todos los front-ends (C, C++, Ada, etc.) generan una **IR compartida** â€”como **GIMPLE o RTL**.

Luego, los back-ends especÃ­ficos de cada arquitectura (x86, ARM, 68k, etc.) traducen esa **IR a cÃ³digo nativo**.

| Parte del compilador | FunciÃ³n principal                  | Ejemplo      |
| :------------------- | :--------------------------------- | :----------- |
| **Front-end**        | Traduce el lenguaje fuente a IR    | C â†’ GIMPLE   |
| **IR**               | RepresentaciÃ³n comÃºn y optimizable | GIMPLE / RTL |
| **Back-end**         | Traduce IR a cÃ³digo mÃ¡quina        | GIMPLE â†’ x86 |

ğŸŒ³ Una **IR compartida** funciona como un puente entre los front-ends y los back-ends, permitiendo combinar muchos lenguajes y arquitecturas sin crear compiladores desde cero ğŸ”§ğŸ’¡.

<br/><hr/><br/>

## 9. âš¡ OptimizaciÃ³n (Optimization)

> Optimizar un programa significa hacerlo mÃ¡s rÃ¡pido o eficiente sin cambiar lo que hace ğŸ”„.

Un ejemplo simple de optimizaciÃ³n es el **plegado de constantes (constant folding)** ğŸ”¢: si una expresiÃ³n siempre da el mismo resultado, el compilador puede calcularla antes de ejecutar el programa:

```java
area = 3.14159 * (0.75 / 2) * (0.75 / 2);

se puede reemplazar por:

area = 0.4417860938;
```

Aunque la optimizaciÃ³n es importante, muchos lenguajes como Lua o CPython hacen pocas optimizaciones en tiempo de compilaciÃ³n y se enfocan en el rendimiento en tiempo de ejecuciÃ³n.

Algunos conceptos clave de optimizaciÃ³n: Constant propagation - EliminaciÃ³n de expresiones comunes - Movimiento de cÃ³digo invariante de bucle - EliminaciÃ³n de cÃ³digo muerto - Desenrollado de bucles ...

ğŸ’¡ Tip tÃ©cnico:

- La **optimizaciÃ³n** puede ser **local** (dentro de un bloque), **global** (en funciones o mÃ³dulos) o **dependiente del hardware**. Incluso pequeÃ±as mejoras pueden hacer tu cÃ³digo mÃ¡s rÃ¡pido y eficiente.

ğŸŒ³ AST / IR optimizado â†’ ğŸš€ CÃ³digo mÃ¡s rÃ¡pido

<br/><hr/><br/>

## 10. ğŸ’» GeneraciÃ³n de CÃ³digo (Code Generation)

DespuÃ©s de aplicar todas las optimizaciones, el Ãºltimo paso es convertir el programa en algo que la mÃ¡quina pueda ejecutar. Esto se llama **generaciÃ³n de cÃ³digo**, y aquÃ­ â€œcÃ³digoâ€ significa instrucciones primitivas que la CPU entiende, no el cÃ³digo que un humano lee.

Estamos en el back-end del compilador, nuestra representaciÃ³n del programa se vuelve cada vez mÃ¡s simple, acercÃ¡ndose a lo que la mÃ¡quina puede ejecutar.

- Tenemos una decisiÃ³n importante: **Â¿generamos cÃ³digo para una CPU real o para una mÃ¡quina virtual?**

  - **CÃ³digo nativo (CPU real)**: Es ultra rÃ¡pido, pero difÃ­cil de generar; Cada arquitectura tiene sus propias instrucciones, pipelines y â€œequipaje histÃ³ricoâ€; El compilador queda atado a esa arquitectura (ej. x86 â‰  ARM).

  - **CÃ³digo para mÃ¡quina virtual / bytecode**: En lugar de un chip real, generamos instrucciones para una mÃ¡quina idealizada; MÃ¡s portable, mÃ¡s fÃ¡cil de implementar y mÃ¡s cercano a la semÃ¡ntica del lenguaje; Ejemplo: Java, Python o Lua usan bytecode para funcionar en diferentes plataformas.

ğŸ—ï¸ **Apunte tÃ©cnico**:
La **generaciÃ³n de cÃ³digo** convierte la representaciÃ³n intermedia optimizada en instrucciones ejecutables, ya sea para CPU real con mÃ¡ximo rendimiento, pero depende de la arquitectura, o bien para mÃ¡quina virtual / bytecode que son mÃ¡s portable y fÃ¡cil de implementar.

> **Generar cÃ³digo** es el Ãºltimo paso que hace que nuestro programa â€œvivaâ€ en la mÃ¡quina.

<br/><hr/><br/>

## 11. ğŸ–¥ï¸ MÃ¡quina Virtual (Virtual Machine â€“ VM)

Si tu compilador genera **bytecode**, todavÃ­a queda un paso: traducirlo a algo que la mÃ¡quina pueda ejecutar. Como no existe un chip que lo entienda directamente, tienes dos caminos.

- El primero es hacer **mini-compiladores** para cada arquitectura. Cada **compilador** convierte el **bytecode en cÃ³digo nativo** para un chip especÃ­fico. Es relativamente sencillo y rÃ¡pido, y puedes reutilizar gran parte del pipeline del compilador. Sin embargo, todavÃ­a hay que trabajar por cada arquitectura, porque cada CPU tiene su propio "idioma".

- El segundo camino es construir una **mÃ¡quina virtual (VM)**. En lugar de traducir el **bytecode** de una vez, creas un programa que simula un chip hipotÃ©tico capaz de ejecutar tu bytecode. Esto es mÃ¡s lento porque cada instrucciÃ³n **se interpreta** en tiempo real, pero es mucho mÃ¡s portable y sencillo: mientras tu VM funcione en una plataforma, tu lenguaje tambiÃ©n lo harÃ¡. Es la estrategia que usan lenguajes como Java, Python y Lua.

> En pocas palabras: Usar bytecode + VM significa portabilidad y reutilizaciÃ³n. AdemÃ¡s de generar cÃ³digo nativo da mÃ¡ximo rendimiento. El desafÃ­o siempre es encontrar el equilibrio entre velocidad y compatibilidad.

<br/><hr/><br/>

## 12. â±ï¸ Tiempo de EjecuciÃ³n (Runtime)

Finalmente, tu programa estÃ¡ listo para ejecutarse.

- Si lo **compilaste a cÃ³digo mÃ¡quina**, simplemente el sistema operativo carga el ejecutable y Â¡listo!.

- Si lo **compilaste a bytecode**, necesitas arrancar la mÃ¡quina virtual (VM) y cargar el programa allÃ­.

Pero casi todos los lenguajes, excepto los mÃ¡s bÃ¡sicos, necesitan **servicios adicionales** durante la ejecuciÃ³n. Por ejemplo, si el lenguaje maneja memoria automÃ¡ticamente, se requiere un **garbage collector** â™»ï¸. Si soporta tipos dinÃ¡micos, debe mantener informaciÃ³n sobre los objetos y su tipo.

Esto es lo que llamamos **runtime â±ï¸**. En un **lenguaje totalmente compilado**, el runtime se incrusta dentro del ejecutable, como sucede en Go. En lenguajes que corren en una VM o intÃ©rprete, el runtime vive allÃ­, como Java, Python o JavaScript.

En pocas palabras, el **runtime** proporciona los **servicios** que tu programa necesita para funcionar correctamente, como gestiÃ³n de memoria, rastreo de tipos y acceso a librerÃ­as estÃ¡ndar.

> Resumen rÃ¡pido: **Compilador + VM/IntÃ©rprete + Runtime = ejecuciÃ³n completa**.

<br/><hr/><br/>

## 13. ğŸ›£ï¸ Atajos y rutas alternativas

El camino que hemos recorrido es el largo y completo, cubriendo todas las fases posibles. Sin embargo, algunos lenguajes usan atajos para simplificar las cosas.

Algunos usan **compiladores de un solo paso**. En estos, parsing, anÃ¡lisis y generaciÃ³n de cÃ³digo se combinan en un solo flujo: no se crean Ã¡rboles intermedios ni estructuras complicadas. Esto obliga a que cada expresiÃ³n se pueda compilar en el momento exacto en que se ve. Lenguajes clÃ¡sicos como Pascal y C fueron diseÃ±ados con estas limitaciones en mente. Por ejemplo, en C necesitas declarar funciones antes de usarlas.

Otra tÃ©cnica es la **traducciÃ³n dirigida por la sintaxis**. AquÃ­, cada regla de la gramÃ¡tica tiene asociada una acciÃ³n, normalmente generar cÃ³digo. Cada vez que el parser reconoce esa regla, ejecuta la acciÃ³n y construye el programa paso a paso.

> Los **compiladores de un solo paso** combinan parsing, anÃ¡lisis y generaciÃ³n de cÃ³digo en un Ãºnico flujo eficiente, sin fases intermedias.

<br/><hr/><br/>

## 14. ğŸŒ³ IntÃ©rpretes de recorrido de Ã¡rbol (Tree-walk interpreters)

Algunos lenguajes ejecutan el programa directamente desde el **AST (Ã¡rbol de sintaxis abstracta)** justo despuÃ©s de parsearlo. El intÃ©rprete recorre el Ã¡rbol rama por rama y hoja por hoja, evaluando cada nodo.

Este enfoque es ideal para proyectos pequeÃ±os o educativos, porque es fÃ¡cil de entender. Sin embargo, no es muy rÃ¡pido. **Nuestro primer intÃ©rprete serÃ¡ de este tipo**, decir que versiones tempranas de Ruby tambiÃ©n usaban este mÃ©todo. Luego, Ruby 1.9 cambiÃ³ a YARV, una VM de bytecode, para mejorar velocidad y portabilidad.

> Por lo tanto, los **tree-walk interpreters** son educativos y simples, pero lentos. Para lenguajes modernos se prefiere compilar a bytecode y ejecutarlo en una VM, lo que combina eficiencia y portabilidad.

<br/><hr/><br/>

## 15. ğŸ”„ Transpilador (Transpiler)

Escribir un back-end completo para un lenguaje puede ser mucho trabajo. Una alternativa es usar un lenguaje existente como objetivo, tratÃ¡ndolo como si fuera una representaciÃ³n intermedia (IR). Esto es bÃ¡sicamente lo que hace un transpiler.

**Â¿CÃ³mo funciona un transpiler?**:
Primero, escribes un front-end para tu lenguaje (scanner y parser). Luego, en lugar de generar directamente cÃ³digo mÃ¡quina, produces cÃ³digo fuente vÃ¡lido en otro lenguaje que estÃ© a un nivel similar al tuyo. Finalmente, utilizas las herramientas de compilaciÃ³n existentes de ese lenguaje para llegar a un programa ejecutable.

Antes se llamaba **source-to-source compiler** o **transcompiler**, pero hoy en dÃ­a, gracias a lenguajes que compilan a JavaScript para navegadores, se les dice **transpilers**. Originalmente, muchos compiladores generaban C como lenguaje de salida, porque era portable y eficiente. Hoy, los navegadores son las â€œmÃ¡quinasâ€ y su â€œcÃ³digo mÃ¡quinaâ€ es JavaScript, por lo que casi todos los lenguajes modernos apuntan a JS.

**Â¿CÃ³mo funciona internamente?**:
Si el lenguaje fuente es muy parecido al destino, el transpiler puede saltar anÃ¡lisis y generar la sintaxis equivalente directamente. Si hay diferencias semÃ¡nticas, se aplican fases tÃ­picas de compilaciÃ³n, incluyendo anÃ¡lisis y optimizaciÃ³n. En la generaciÃ³n de cÃ³digo, en lugar de producir binario, se produce una cadena de cÃ³digo fuente correcta en el lenguaje destino. Luego, ese cÃ³digo se procesa con el pipeline del lenguaje destino y listo.

**ğŸ’¡ Apunte tÃ©cnico:**
Un **transpiler** es un compilador que apunta a otro lenguaje de alto nivel, usando ese lenguaje como una IR intermedia. Esto evita tener que escribir un back-end completo y permite aprovechar las herramientas existentes del lenguaje destino.

**Front-end â†’ CÃ³digo fuente destino â†’ CompilaciÃ³n existente â†’ EjecuciÃ³n**

<br/><hr/><br/>

## 16. âœ¨ CompilaciÃ³n Just-in-Time (JIT)

Este enfoque es como una escalada alpina peligrosa, mejor para expertos. El cÃ³digo mÃ¡s rÃ¡pido siempre serÃ¡ el que estÃ© compilado a cÃ³digo mÃ¡quina, pero a veces no sabes de antemano la arquitectura del usuario final.

ğŸ’¡ La soluciÃ³n: **CompilaciÃ³n Just-in-Time (JIT)**. Cuando el programa se carga en la mÃ¡quina del usuario â€”ya sea desde cÃ³digo fuente (como JavaScript) o desde bytecode independiente de plataforma (JVM, CLR)â€” se compila al vuelo a cÃ³digo nativo para esa arquitectura. Es decir, el programa se adapta al hardware real del usuario y se ejecuta lo mÃ¡s rÃ¡pido posible.

ğŸ” OptimizaciÃ³n avanzada en JIT: Los JIT mÃ¡s sofisticados aÃ±aden **hooks** de perfilado en el cÃ³digo, que permiten ver quÃ© partes del programa se usan mÃ¡s y quÃ© tipo de datos pasan por ellas. Esas **â€œzonas calientesâ€ o hot spots** se pueden recompilar automÃ¡ticamente con optimizaciones adicionales, aumentando la velocidad de ejecuciÃ³n.

- **JIT** combina **portabilidad** del bytecode con la **velocidad** del cÃ³digo nativo. Permite adaptarse dinÃ¡micamente al hardware del usuario, optimizando solo lo que realmente importa.

Muchos lenguajes modernos como Java, C#, JavaScript y Ruby (YARV) usan JIT para maximizar rendimiento sin perder portabilidad.

- **JIT = cargar cÃ³digo â†’ compilar a nativo en tiempo real â†’ perfilado y recompilaciÃ³n de hot spots**

<br/><hr/><br/>

## 17. ğŸ“š Compiladores e IntÃ©rpretes (Compilers and Interpreters)

DespuÃ©s de llenar tu cabeza con toda la jerga de compiladores, mÃ¡quinas virtuales y runtimes, llega la gran pregunta: **â€œÂ¿CuÃ¡l es la diferencia entre un compilador y un intÃ©rprete?â€**

La diferencia entre un compilador y un intÃ©rprete es como diferenciar entre un coche automÃ¡tico y uno manual ğŸš—. Parece una elecciÃ³n binaria, pero no lo es: un coche automÃ¡tico cambia de marchas solo, mientras que uno manual requiere que el conductor haga los cambios. Algunos coches modernos tienen modos mixtos, como semiautomÃ¡tico, que combinan lo mejor de ambos mundos.

Lo mismo pasa con los lenguajes: algunos son puramente compilados, otros puramente interpretados, y muchos modernos mezclan ambos enfoques.

> **En cuanto a lenguajes de programaciÃ³n:**

**Compilar** significa traducir tu cÃ³digo a otro lenguaje, generalmente mÃ¡s bajo.
Generar bytecode o cÃ³digo mÃ¡quina = compilar.
Transpilar a otro lenguaje de alto nivel = tambiÃ©n compilar.

Una implementaciÃ³n que **solo traduce** pero no ejecuta el cÃ³digo es un **compilador**.

Una implementaciÃ³n que **ejecuta** directamente el cÃ³digo fuente es un **intÃ©rprete**.

**Ejemplos:**

**GCC o Clang** â†’ traducen C a cÃ³digo mÃ¡quina. El usuario ejecuta el programa resultante. Son **compiladores**.

**Ruby (Matz)** â†’ ejecuta el cÃ³digo fuente directamente. El **intÃ©rprete** recorre el AST. No hay traducciÃ³n visible, es un **intÃ©rprete**.

**CPython (Python)** â†’ convierte el cÃ³digo a bytecode interno y luego lo ejecuta en la VM. Desde la perspectiva del usuario, es un **intÃ©rprete**, pero bajo el capÃ³ tambiÃ©n hay **compilaciÃ³n**. ConclusiÃ³n: **es ambos**.

> **ğŸ§© Apunte tÃ©cnico:**

La mayorÃ­a de lenguajes modernos **mezclan interpretaciÃ³n y compilaciÃ³n**.

Cuando hagamos nuestro **segundo intÃ©rprete** tambiÃ©n compila a bytecode, asÃ­ que aunque hablemos de intÃ©rprete, la compilaciÃ³n tambiÃ©n estÃ¡ presente. La lÃ­nea entre compilador e intÃ©rprete no siempre es nÃ­tida.

Conceptos como bytecode y JIT muestran que muchos lenguajes modernos combinan ambos enfoques.

Al diseÃ±ar un lenguaje o intÃ©rprete, es Ãºtil pensar en fases de compilaciÃ³n y ejecuciÃ³n mÃ¡s que en etiquetas estrictas.

Concluyo que:

- **Compilador = traduce a otra forma**

- **IntÃ©rprete = ejecuta desde el cÃ³digo fuente**

- **Lenguajes modernos = mezcla de ambos**

<br/><hr/><br/>

## 18. ğŸ“ Ejercicio Propuesto (en desarrollo)

- Ejercio Propuesto 1: Explorando Scanners y Parsers

  **Objetivo**: Familiarizarse con la implementaciÃ³n real de compiladores e intÃ©rpretes explorando cÃ³digo open source.

  **Instrucciones**: Elige un lenguaje open source de tu preferencia. Por ejemplo, puedes usar uno de estos repositorios en GitHub: - [CPython (Python) â€“ El intÃ©rprete oficial de Python en C](https://github.com/python/cpython) - [PyPy (Python JIT) â€“ ImplementaciÃ³n alternativa de Python con JIT](https://github.com/friendlyanon/pypy) - [MRI (Ruby) â€“ ImplementaciÃ³n oficial de Ruby (Matzâ€™s Ruby Interpreter)](https://github.com/ruby/ruby) - [JRuby â€“ Ruby sobre JVM](https://github.com/jruby/jruby) - [Lua â€“ Lenguaje ligero, famoso por embebirse en juegos](https://github.com/lua/lua) - [GHC (Glasgow Haskell Compiler) â€“ Compilador de Haskell](https://github.com/ghc/ghc) - [Go (golang) â€“ Lenguaje de Google, compilador y runtime incluidos](https://github.com/golang/go) - [V (Vlang) â€“ Lenguaje moderno, compilador muy sencillo de explorar](https://github.com/vlang/v) - [Crystal â€“ Lenguaje tipo Ruby, compilado a cÃ³digo nativo](https://github.com/crystal-lang/crystal) - [Nim â€“ Lenguaje moderno, compilado a C, C++ o JavaScript](https://github.com/nim-lang/Nim)

  **Clona o descarga el repositorio en tu mÃ¡quina**: Clonando con Git
  git clone https://github.com/python/cpython.git
  O descargando el ZIP desde la pÃ¡gina de GitHub y descomprimiÃ©ndolo

  **Explora la estructura de carpetas del repositorio**. Busca carpetas o archivos relacionados con: parser - lexer - scanner - tokenizer - Grammar. AhÃ­ suele estar la magia que convierte el cÃ³digo fuente en tokens y AST.

  **Investiga cÃ³mo se implementan:**
  Â¿QuÃ© significan Lex y Yacc?
  En el lenguaje que estÃ¡s investigando, Â¿existen archivos con extensiÃ³n .l o .y? Eso te indicarÃ¡ si usan Lex/Yacc para generar el scanner y parser.

  **Responde las siguientes preguntas:**
  Â¿CÃ³mo organiza el lenguaje el escaneo y parsing del cÃ³digo fuente?
  Â¿QuÃ© tipo de archivos usa para definir la gramÃ¡tica o las reglas del lexer?
  Â¿Puedes identificar la funciÃ³n que recibe el texto y devuelve los tokens?
  Â¿Puedes identificar la funciÃ³n que construye el AST?

<br/><hr/><br/>

| [â†©ï¸ Volver al inicio del Proyecto](../README.md) | [â¬†ï¸ Ir al inicio del CapÃ­tulo](#capitulo-2-las-piezas-que-componen-un-lenguaje) | [â¬…ï¸ Ir a CapÃ­tulo 1](../docs/01-Bienvenido.md) |
| :----------------------------------------------: | :-----------------------------------------------------------------------------: | :--------------------------------------------: |
